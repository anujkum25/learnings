{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19984/3612434534.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def v_wrap(np_array, dtype=np.float32):\n",
    "    if np_array.dtype != dtype:\n",
    "        np_array = np_array.astype(dtype)\n",
    "    return torch.from_numpy(np_array)\n",
    "\n",
    "\n",
    "def normalized_columns_initializer(weights, std=1.0):\n",
    "    out = torch.randn(weights.size())\n",
    "    out *= std / torch.sqrt(out.pow(2).sum(1, keepdim=True))\n",
    "    return out\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        weight_shape = list(m.weight.data.size())\n",
    "        fan_in = np.prod(weight_shape[1:4])\n",
    "        fan_out = np.prod(weight_shape[2:4]) * weight_shape[0]\n",
    "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "        m.weight.data.uniform_(-w_bound, w_bound)\n",
    "        m.bias.data.fill_(0)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        weight_shape = list(m.weight.data.size())\n",
    "        fan_in = weight_shape[1]\n",
    "        fan_out = weight_shape[0]\n",
    "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
    "        m.weight.data.uniform_(-w_bound, w_bound)\n",
    "        m.bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class job_shop_env():\n",
    "    path = '/workspaces/learnings/Job_Shop_Scheduling_Problem_with_Reinforcement_Learning/data/'\n",
    "    expert_job = pd.read_csv(path + 'process_time_matrix.csv',header=None).drop([0]).values\n",
    "    job = pd.read_csv(path + 'work_order.csv',header=None).values\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.job_cluster = self.expert_job.shape[1]\n",
    "        self.expert = self.expert_job.shape[0]\n",
    "        self.job_num = self.job.shape[0]\n",
    "        self.process_time = self.expert_job\n",
    "        self.expert_status = np.repeat(0,self.expert) \n",
    "        self.expert_process_job = [[] for i in range(self.expert)]\n",
    "        self.expert_process_time = [[] for i in range(self.expert)]\n",
    "        self.job_waiting_time = [[] for i in range(self.expert)]\n",
    "        self.left_job = self.job.shape[0]\n",
    "        self.done = False\n",
    "        self.total_time = 0  \n",
    "        self.job_distribute_time = np.repeat(0,self.job.shape[0])\n",
    "        self.total_job_process_time = np.repeat(0,self.job.shape[0])\n",
    "        self.job_status = np.repeat(1,self.job.shape[0])  \n",
    "        self.job_index = list(range(self.job.shape[0]))  \n",
    "        self.timeindex = 0   \n",
    "        self.state = np.vstack((self.job_status,self.job_distribute_time))\n",
    "        self.state = self.state.reshape(self.state.shape[0],self.state.shape[1],1)\n",
    "        self.done_job = [] \n",
    "        self.done_expert = [] \n",
    "        self.job_start_time = [] \n",
    "        self.state_dim = self.state.shape[0]\n",
    "        self.action_dim = 2\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.job_num = self.job.shape[0]\n",
    "        self.expert_status = np.repeat(0,self.expert) \n",
    "        self.expert_process_job = [[] for i in range(self.expert)]\n",
    "        self.expert_process_time = [[] for i in range(self.expert)]\n",
    "        self.job_waiting_time = [[] for i in range(self.expert)]\n",
    "        #self.left_job = self.job.shape[0]\n",
    "        self.done = False\n",
    "        self.total_time = 0  \n",
    "        self.job_distribute_time = np.repeat(0,self.job.shape[0])\n",
    "        self.total_job_process_time = np.repeat(0,self.job.shape[0])\n",
    "        self.job_status = np.repeat(1,self.job.shape[0])  \n",
    "        self.job_index = list(range(self.job.shape[0]))  \n",
    "        #self.timeindex = 0  \n",
    "        self.state = np.vstack((self.job_status,self.job_distribute_time))\n",
    "        self.state = self.state.reshape(self.state.shape[0],self.state.shape[1],1)\n",
    "        self.done_job = []\n",
    "        self.done_expert = [] \n",
    "        self.job_start_time = [] \n",
    "        \n",
    "        return self.state\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        job_id = np.random.choice(a=self.job_num, size=self.expert, replace=False, p=None)\n",
    "        for i in job_id:\n",
    "            if len(self.job_index) != 0:\n",
    "                if i in self.job_index:\n",
    "                    self.job_distribute_time[i] += 1\n",
    "                    ## if more than 2, delete this job\n",
    "                    #if self.job_distribute_time[i] >= 2:\n",
    "                    #    del self.job_index[self.job_index.index(i)]\n",
    "                else:\n",
    "                    job_id[job_id.tolist().index(i)] = random.sample(self.job_index,1)[0]\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        assert action.shape[0] == self.expert\n",
    "        \n",
    "        for i in range(self.expert):\n",
    "            ## only process those jobs that are in job_index\n",
    "            if job_id[i] in self.job_index:\n",
    "                ## action = 0 indicates do not give jobs to the expert\n",
    "                if action[i] == 0 or self.expert_status[i] == 3:\n",
    "                    pass\n",
    "                else:\n",
    "                    self.expert_process_job[i].append(job_id[i])\n",
    "                    self.expert_status[i] += 1\n",
    "                    self.job_status[job_id[i]] = 0\n",
    "                    self.expert_process_time[i].append(0)\n",
    "                    # how much time a job wait before processing\n",
    "                    self.job_waiting_time[i].append(self.timeindex)\n",
    "                    # if expert could not handle the job, exit\n",
    "                    self.total_job_process_time[job_id[i]] = self.process_time[i][self.job[job_id[i]][2]]\n",
    "                \n",
    "                delete_index = []\n",
    "                for j in range(len(self.expert_process_time[i])):\n",
    "                    if len(self.expert_process_job[i]) != 0:\n",
    "                        if self.expert_process_time[i][j] == self.process_time[i][self.job[self.expert_process_job[i][j]][2]]:\n",
    "                            # if job finished, workload of expert would decrease\n",
    "                            self.expert_status[i] -= 1\n",
    "                            self.done_expert.append(i)\n",
    "                            if self.expert_process_job[i][j] not in self.done_job:\n",
    "                                self.left_job -= 1\n",
    "                            self.done_job.append(self.expert_process_job[i][j])\n",
    "                            ## calculate when the job starts to be processed by subtracting the process time\n",
    "                            self.job_start_time.append(self.job_waiting_time[i][j] + self.job[self.expert_process_job[i][j]][1])\n",
    "                            delete_index.append(j)\n",
    "                if len(delete_index) > 0:\n",
    "                    if len(delete_index) > 1:\n",
    "                        delete_index.sort(reverse = True)\n",
    "                    for k in delete_index:\n",
    "                        del self.expert_process_job[i][k]\n",
    "                        del self.expert_process_time[i][k]\n",
    "            ## calculate total time consumed\n",
    "            self.total_time += sum(self.job_waiting_time[i]) + self.total_job_process_time[i].sum()\n",
    "            self.expert_process_time[i] = [m + 1 for m in self.expert_process_time[i]]\n",
    "        \n",
    "        ## reward takes the minus of total time*0.001 and left job num\n",
    "        #print(self.total_time)\n",
    "        reward = 1 - self.left_job/self.job_num\n",
    "        self.timeindex += 1\n",
    "        \n",
    "        ## update state info\n",
    "        self.state = np.vstack((self.job_status,self.job_distribute_time))\n",
    "        self.state = self.state.reshape(self.state.shape[0],self.state.shape[1],1)\n",
    "        \n",
    "        if self.left_job == 0:\n",
    "            self.done = True\n",
    "        #print(self.expert_status)\n",
    "        #print(self.expert_process_job)\n",
    "        #print(self.done_job)\n",
    "        return self.state, reward, self.done, self.done_job, self.done_expert, self.job_start_time\n",
    "\n",
    "    def update(self,delete_list):\n",
    "        if len(delete_list) != 0:\n",
    "            for i in delete_list:\n",
    "                if i in self.job_index:\n",
    "                    self.job_index.remove(i)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ActorCritic(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, action_space):\n",
    "        super(ActorCritic, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_inputs, 32, 3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
    "\n",
    "        self.lstm = nn.LSTMCell(32*553, 256)\n",
    "\n",
    "        num_outputs = action_space\n",
    "        self.critic_linear = nn.Linear(256, 1)\n",
    "        self.actor_linear = nn.Linear(256, num_outputs)\n",
    "\n",
    "        self.apply(weights_init)\n",
    "        self.actor_linear.weight.data = normalized_columns_initializer(\n",
    "            self.actor_linear.weight.data, 0.01)\n",
    "        self.actor_linear.bias.data.fill_(0)\n",
    "        self.critic_linear.weight.data = normalized_columns_initializer(\n",
    "            self.critic_linear.weight.data, 1.0)\n",
    "        self.critic_linear.bias.data.fill_(0)\n",
    "\n",
    "        self.lstm.bias_ih.data.fill_(0)\n",
    "        self.lstm.bias_hh.data.fill_(0)\n",
    "\n",
    "        self.train()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs, (hx, cx) = inputs\n",
    "        x = F.relu(self.conv1(inputs))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "\n",
    "        x = x.view(-1, 32*553)\n",
    "        hx, cx = self.lstm(x, (hx, cx))\n",
    "        x = hx\n",
    "\n",
    "        return self.critic_linear(x), self.actor_linear(x), (hx, cx)\n",
    "    \n",
    "    def choose_action(self,inputs,action_dim):\n",
    "        s, (hx, cx) = inputs\n",
    "        value, logit, (hx, cx) = self.forward((s.unsqueeze(0),(hx, cx)))\n",
    "        prob = F.softmax(logit, dim=-1)\n",
    "        log_prob = F.log_softmax(logit, dim=-1)\n",
    "        entropy = -(log_prob * prob).sum(1, keepdim=True)\n",
    "        \n",
    "        #action = prob.multinomial(num_samples=action_dim).detach()\n",
    "        action=[]\n",
    "        for i in range(action_dim):\n",
    "            action.append(prob.multinomial(num_samples=1).detach()[0])\n",
    "        action = torch.from_numpy(np.array(action,dtype = np.int64).reshape(1,133))\n",
    "        return action, log_prob, entropy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(args):\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    env = job_shop_env()\n",
    "    \n",
    "    model = ActorCritic(env.state_dim, env.action_dim)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    state = env.reset()\n",
    "    state = v_wrap(state)\n",
    "    done = True\n",
    "    action_dim = env.expert\n",
    "\n",
    "    episode_length = 0\n",
    "    complete_jobs = []\n",
    "    expert_complete_job = []\n",
    "    complete_job_start_time = []\n",
    "    update_list = []\n",
    "    for episode in range(args.episode):\n",
    "        \n",
    "        if done:\n",
    "            cx = torch.zeros(1, 256)\n",
    "            hx = torch.zeros(1, 256)\n",
    "        else:\n",
    "            cx = cx.detach()\n",
    "            hx = hx.detach()\n",
    "        \n",
    "        if len(complete_jobs) != 0:\n",
    "            update_list = [n for m in complete_jobs for n in m]\n",
    "            env.update(update_list)\n",
    "\n",
    "        values = []\n",
    "        log_probs = []\n",
    "        rewards = []\n",
    "        entropies = []\n",
    "\n",
    "        for step in range(args.num_steps+1):\n",
    "            episode_length += 1\n",
    "            \n",
    "\n",
    "            action, log_prob, entropy, value = model.choose_action((state, (hx,cx)),action_dim)\n",
    "            log_prob = log_prob.gather(1, action)[0]\n",
    "            \n",
    "            state, reward, done, done_job, done_expert, job_start_time = env.step(action.view(-1,).numpy())\n",
    "            done = done or episode_length >= args.max_episode_length\n",
    "            ## reward shaping\n",
    "            reward = max(min(reward, 1), -1)\n",
    "            if episode_length % 20 == 0:\n",
    "                print(reward)\n",
    "                #print(done_job)\n",
    "\n",
    "            if done:\n",
    "                complete_jobs.append(done_job)\n",
    "                expert_complete_job.append(done_expert)\n",
    "                complete_job_start_time.append(job_start_time)\n",
    "                print('Complete these jobs with 100 iterations:')\n",
    "                print(complete_jobs)\n",
    "                print('Current episode:',episode)\n",
    "                episode_length = 0\n",
    "                state = env.reset()\n",
    "\n",
    "            state = v_wrap(state)\n",
    "            values.append(value)\n",
    "            log_probs.append(log_prob)\n",
    "            rewards.append(reward)\n",
    "            entropies.append(entropy)\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        if len(list(set(update_list))) > 8800:\n",
    "            ## write results into the csv file\n",
    "            with open('submit_{}.csv'.format(len(list(set(update_list)))),'w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for i in range(len(complete_jobs)):\n",
    "                    for j in range(len(complete_jobs[i])):\n",
    "                        writer.writerow([complete_jobs[i][j]+1, expert_complete_job[i][j]+1, complete_job_start_time[i][j]])\n",
    "\n",
    "        if episode == args.episode -1 or len(list(set(update_list))) == 8840:\n",
    "            ## write results into the csv file\n",
    "            with open('submit.csv','w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                for i in range(len(complete_jobs)):\n",
    "                    for j in range(len(complete_jobs[i])):\n",
    "                        writer.writerow([complete_jobs[i][j]+1, expert_complete_job[i][j]+1, complete_job_start_time[i][j]])\n",
    "            break\n",
    "\n",
    "        R = torch.zeros(1, 1)\n",
    "        if not done:\n",
    "            value, _, _ = model((state.unsqueeze(0), (hx, cx)))\n",
    "            R = value.detach()\n",
    "\n",
    "        values.append(R)\n",
    "        policy_loss = 0\n",
    "        value_loss = 0\n",
    "        gae = torch.zeros(1, 1)\n",
    "        for i in reversed(range(len(rewards))):\n",
    "            R = args.gamma * R + rewards[i]\n",
    "            advantage = R - values[i]\n",
    "            value_loss = value_loss + 0.5 * advantage.pow(2)\n",
    "\n",
    "            # Generalized Advantage Estimation\n",
    "            delta_t = rewards[i] + args.gamma * \\\n",
    "                values[i + 1] - values[i]\n",
    "            gae = gae * args.gamma * args.gae_lambda + delta_t\n",
    "\n",
    "            policy_loss = policy_loss - \\\n",
    "                log_probs[i] * gae.detach() - args.entropy_coef * entropies[i]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        (policy_loss + args.value_loss_coef * value_loss).backward(torch.ones_like(policy_loss))\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "        print(policy_loss.mean() + args.value_loss_coef * value_loss)\n",
    "        print('para updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='JSSPRL')\n",
    "parser.add_argument('--lr', type=float, default=0.0001,\n",
    "                    help='learning rate (default: 0.0001)')\n",
    "parser.add_argument('--gamma', type=float, default=0.99,\n",
    "                    help='discount factor for rewards (default: 0.99)')\n",
    "parser.add_argument('--gae-lambda', type=float, default=1.00,\n",
    "                    help='lambda parameter for GAE (default: 1.00)')\n",
    "parser.add_argument('--entropy-coef', type=float, default=0.01,\n",
    "                    help='entropy term coefficient (default: 0.01)')\n",
    "parser.add_argument('--value-loss-coef', type=float, default=0.5,\n",
    "                    help='value loss coefficient (default: 0.5)')\n",
    "parser.add_argument('--max-grad-norm', type=float, default=50,\n",
    "                    help='value loss coefficient (default: 50)')\n",
    "parser.add_argument('--seed', type=int, default=1,\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--num-steps', type=int, default=20,\n",
    "                    help='number of forward steps in A3C (default: 20)')\n",
    "parser.add_argument('--max-episode-length', type=int, default=1000000,\n",
    "                    help='maximum length of an episode (default: 1000000)')\n",
    "parser.add_argument('--episode', type=int, default=10,\n",
    "                    help='How many episode to train the RL algorithm')\n",
    "\n",
    "#args = parser.parse_args()\n",
    "print('start training...')\n",
    "#train(args)\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    \n",
    "#    args = parser.parse_args()\n",
    "#    print('start training...')\n",
    "#    train(args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "0.0007918552036199067\n",
      "0.002149321266968318\n",
      "0.0039592760180995334\n",
      "0.005429864253393646\n",
      "0.006674208144796356\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680]]\n",
      "Current episode: 0\n",
      "tensor([[1.3647]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.007692307692307665\n",
      "0.009728506787330282\n",
      "0.011312217194570096\n",
      "0.012443438914027105\n",
      "0.013687782805429816\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249]]\n",
      "Current episode: 1\n",
      "tensor([[373.4995]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.014819004524886825\n",
      "0.016176470588235348\n",
      "0.017986425339366563\n",
      "0.019230769230769273\n",
      "0.02013574660633488\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875]]\n",
      "Current episode: 2\n",
      "tensor([[-44.6138]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.021493212669683293\n",
      "0.022850678733031704\n",
      "0.024321266968325816\n",
      "0.025226244343891424\n",
      "0.026583710407239836\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875], [8210, 5913, 3457, 227, 5045, 7978, 3822, 8361, 2331, 8057, 8230, 541, 5276, 4100, 8771, 3425, 5492, 1226, 1384, 7377, 1395, 4625, 6782, 2014, 2298, 214, 3355, 5957, 4416, 5659, 648, 5024, 5569, 6245, 8716, 5899, 6636, 8651, 6099, 8072, 8471, 2135, 7142, 5997, 1077, 8713, 2497, 1435, 7401, 350, 5319, 6326, 2673, 6676, 695, 5773, 3678]]\n",
      "Current episode: 3\n",
      "tensor([[42.0928]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.027828054298642546\n",
      "0.029864253393665163\n",
      "0.030995475113122173\n",
      "0.03223981900452488\n",
      "0.033597285067873295\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875], [8210, 5913, 3457, 227, 5045, 7978, 3822, 8361, 2331, 8057, 8230, 541, 5276, 4100, 8771, 3425, 5492, 1226, 1384, 7377, 1395, 4625, 6782, 2014, 2298, 214, 3355, 5957, 4416, 5659, 648, 5024, 5569, 6245, 8716, 5899, 6636, 8651, 6099, 8072, 8471, 2135, 7142, 5997, 1077, 8713, 2497, 1435, 7401, 350, 5319, 6326, 2673, 6676, 695, 5773, 3678], [6574, 3879, 8522, 7313, 5582, 7972, 7355, 5745, 7565, 8269, 5003, 5853, 549, 4271, 4832, 6727, 322, 7905, 5204, 6621, 8398, 708, 4405, 6361, 2144, 1709, 3740, 5210, 6812, 3645, 5922, 5019, 2990, 323, 4531, 6785, 6117, 7318, 4901, 765, 3889, 4443, 1987, 4974, 8567, 7559, 428, 1763, 7539, 3898, 687, 4168, 6899, 4875, 7287, 493, 711, 5594, 8606, 2250, 5029, 2526]]\n",
      "Current episode: 4\n",
      "tensor([[10.4624]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.034728506787330304\n",
      "0.03653846153846152\n",
      "0.03778280542986423\n",
      "0.03868778280542984\n",
      "0.03993212669683255\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875], [8210, 5913, 3457, 227, 5045, 7978, 3822, 8361, 2331, 8057, 8230, 541, 5276, 4100, 8771, 3425, 5492, 1226, 1384, 7377, 1395, 4625, 6782, 2014, 2298, 214, 3355, 5957, 4416, 5659, 648, 5024, 5569, 6245, 8716, 5899, 6636, 8651, 6099, 8072, 8471, 2135, 7142, 5997, 1077, 8713, 2497, 1435, 7401, 350, 5319, 6326, 2673, 6676, 695, 5773, 3678], [6574, 3879, 8522, 7313, 5582, 7972, 7355, 5745, 7565, 8269, 5003, 5853, 549, 4271, 4832, 6727, 322, 7905, 5204, 6621, 8398, 708, 4405, 6361, 2144, 1709, 3740, 5210, 6812, 3645, 5922, 5019, 2990, 323, 4531, 6785, 6117, 7318, 4901, 765, 3889, 4443, 1987, 4974, 8567, 7559, 428, 1763, 7539, 3898, 687, 4168, 6899, 4875, 7287, 493, 711, 5594, 8606, 2250, 5029, 2526], [1205, 7547, 1472, 2012, 4031, 5965, 5173, 8302, 2333, 3392, 3359, 8542, 2381, 3858, 1460, 376, 1988, 6418, 4846, 4897, 8723, 3580, 978, 7863, 1478, 2783, 1220, 5918, 3219, 3722, 4299, 5540, 6323, 3473, 2494, 7606, 3314, 6776, 500, 1762, 1259, 5740, 4845, 4680, 2760, 1064, 7105, 4374, 3302, 6989, 4864, 2550, 3735, 34, 5845, 3245]]\n",
      "Current episode: 5\n",
      "tensor([[-7.1496]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.04151583710407236\n",
      "0.04400452488687778\n",
      "0.0462669683257918\n",
      "0.04694570135746612\n",
      "0.04751131221719462\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875], [8210, 5913, 3457, 227, 5045, 7978, 3822, 8361, 2331, 8057, 8230, 541, 5276, 4100, 8771, 3425, 5492, 1226, 1384, 7377, 1395, 4625, 6782, 2014, 2298, 214, 3355, 5957, 4416, 5659, 648, 5024, 5569, 6245, 8716, 5899, 6636, 8651, 6099, 8072, 8471, 2135, 7142, 5997, 1077, 8713, 2497, 1435, 7401, 350, 5319, 6326, 2673, 6676, 695, 5773, 3678], [6574, 3879, 8522, 7313, 5582, 7972, 7355, 5745, 7565, 8269, 5003, 5853, 549, 4271, 4832, 6727, 322, 7905, 5204, 6621, 8398, 708, 4405, 6361, 2144, 1709, 3740, 5210, 6812, 3645, 5922, 5019, 2990, 323, 4531, 6785, 6117, 7318, 4901, 765, 3889, 4443, 1987, 4974, 8567, 7559, 428, 1763, 7539, 3898, 687, 4168, 6899, 4875, 7287, 493, 711, 5594, 8606, 2250, 5029, 2526], [1205, 7547, 1472, 2012, 4031, 5965, 5173, 8302, 2333, 3392, 3359, 8542, 2381, 3858, 1460, 376, 1988, 6418, 4846, 4897, 8723, 3580, 978, 7863, 1478, 2783, 1220, 5918, 3219, 3722, 4299, 5540, 6323, 3473, 2494, 7606, 3314, 6776, 500, 1762, 1259, 5740, 4845, 4680, 2760, 1064, 7105, 4374, 3302, 6989, 4864, 2550, 3735, 34, 5845, 3245], [5273, 3384, 7898, 8069, 5996, 4826, 2814, 8504, 7809, 3848, 5490, 8386, 5982, 6564, 7636, 1497, 4042, 7862, 6108, 7517, 6611, 4404, 6366, 6116, 3752, 2974, 1650, 4989, 8256, 2528, 3178, 8487, 3908, 2943, 6843, 6660, 5109, 962, 4324, 5361, 884, 3543, 7807, 2030, 110, 5714, 6414, 8544, 7330, 3957, 7837, 3011, 5213, 3847, 5126, 2097, 4905, 1524, 4994, 2900, 2443, 8215, 4472, 3989, 3382, 8312, 2238]]\n",
      "Current episode: 6\n",
      "tensor([[20.5242]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.048755656108597334\n",
      "0.05067873303167425\n",
      "0.052375565610859764\n",
      "0.053733031674208176\n",
      "0.05441176470588238\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875], [8210, 5913, 3457, 227, 5045, 7978, 3822, 8361, 2331, 8057, 8230, 541, 5276, 4100, 8771, 3425, 5492, 1226, 1384, 7377, 1395, 4625, 6782, 2014, 2298, 214, 3355, 5957, 4416, 5659, 648, 5024, 5569, 6245, 8716, 5899, 6636, 8651, 6099, 8072, 8471, 2135, 7142, 5997, 1077, 8713, 2497, 1435, 7401, 350, 5319, 6326, 2673, 6676, 695, 5773, 3678], [6574, 3879, 8522, 7313, 5582, 7972, 7355, 5745, 7565, 8269, 5003, 5853, 549, 4271, 4832, 6727, 322, 7905, 5204, 6621, 8398, 708, 4405, 6361, 2144, 1709, 3740, 5210, 6812, 3645, 5922, 5019, 2990, 323, 4531, 6785, 6117, 7318, 4901, 765, 3889, 4443, 1987, 4974, 8567, 7559, 428, 1763, 7539, 3898, 687, 4168, 6899, 4875, 7287, 493, 711, 5594, 8606, 2250, 5029, 2526], [1205, 7547, 1472, 2012, 4031, 5965, 5173, 8302, 2333, 3392, 3359, 8542, 2381, 3858, 1460, 376, 1988, 6418, 4846, 4897, 8723, 3580, 978, 7863, 1478, 2783, 1220, 5918, 3219, 3722, 4299, 5540, 6323, 3473, 2494, 7606, 3314, 6776, 500, 1762, 1259, 5740, 4845, 4680, 2760, 1064, 7105, 4374, 3302, 6989, 4864, 2550, 3735, 34, 5845, 3245], [5273, 3384, 7898, 8069, 5996, 4826, 2814, 8504, 7809, 3848, 5490, 8386, 5982, 6564, 7636, 1497, 4042, 7862, 6108, 7517, 6611, 4404, 6366, 6116, 3752, 2974, 1650, 4989, 8256, 2528, 3178, 8487, 3908, 2943, 6843, 6660, 5109, 962, 4324, 5361, 884, 3543, 7807, 2030, 110, 5714, 6414, 8544, 7330, 3957, 7837, 3011, 5213, 3847, 5126, 2097, 4905, 1524, 4994, 2900, 2443, 8215, 4472, 3989, 3382, 8312, 2238], [7857, 5684, 3454, 6478, 7839, 3472, 609, 4546, 4062, 6994, 691, 6692, 7264, 1233, 5113, 489, 1889, 6687, 1067, 3516, 6501, 8776, 2548, 8033, 1124, 4051, 5727, 779, 3955, 4837, 2766, 6294, 6646, 4739, 5749, 6327, 858, 8677, 3651, 596, 6619, 5346, 8077, 1124, 3334, 3089, 8270, 4658, 3660, 4475, 8059, 2034, 6409, 1417, 3609, 5267, 864, 5271, 4774, 7478, 4750, 6737]]\n",
      "Current episode: 7\n",
      "tensor([[21.7792]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.05554298642533939\n",
      "0.057013574660633504\n",
      "0.05882352941176472\n",
      "0.05995475113122173\n",
      "0.06097285067873304\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875], [8210, 5913, 3457, 227, 5045, 7978, 3822, 8361, 2331, 8057, 8230, 541, 5276, 4100, 8771, 3425, 5492, 1226, 1384, 7377, 1395, 4625, 6782, 2014, 2298, 214, 3355, 5957, 4416, 5659, 648, 5024, 5569, 6245, 8716, 5899, 6636, 8651, 6099, 8072, 8471, 2135, 7142, 5997, 1077, 8713, 2497, 1435, 7401, 350, 5319, 6326, 2673, 6676, 695, 5773, 3678], [6574, 3879, 8522, 7313, 5582, 7972, 7355, 5745, 7565, 8269, 5003, 5853, 549, 4271, 4832, 6727, 322, 7905, 5204, 6621, 8398, 708, 4405, 6361, 2144, 1709, 3740, 5210, 6812, 3645, 5922, 5019, 2990, 323, 4531, 6785, 6117, 7318, 4901, 765, 3889, 4443, 1987, 4974, 8567, 7559, 428, 1763, 7539, 3898, 687, 4168, 6899, 4875, 7287, 493, 711, 5594, 8606, 2250, 5029, 2526], [1205, 7547, 1472, 2012, 4031, 5965, 5173, 8302, 2333, 3392, 3359, 8542, 2381, 3858, 1460, 376, 1988, 6418, 4846, 4897, 8723, 3580, 978, 7863, 1478, 2783, 1220, 5918, 3219, 3722, 4299, 5540, 6323, 3473, 2494, 7606, 3314, 6776, 500, 1762, 1259, 5740, 4845, 4680, 2760, 1064, 7105, 4374, 3302, 6989, 4864, 2550, 3735, 34, 5845, 3245], [5273, 3384, 7898, 8069, 5996, 4826, 2814, 8504, 7809, 3848, 5490, 8386, 5982, 6564, 7636, 1497, 4042, 7862, 6108, 7517, 6611, 4404, 6366, 6116, 3752, 2974, 1650, 4989, 8256, 2528, 3178, 8487, 3908, 2943, 6843, 6660, 5109, 962, 4324, 5361, 884, 3543, 7807, 2030, 110, 5714, 6414, 8544, 7330, 3957, 7837, 3011, 5213, 3847, 5126, 2097, 4905, 1524, 4994, 2900, 2443, 8215, 4472, 3989, 3382, 8312, 2238], [7857, 5684, 3454, 6478, 7839, 3472, 609, 4546, 4062, 6994, 691, 6692, 7264, 1233, 5113, 489, 1889, 6687, 1067, 3516, 6501, 8776, 2548, 8033, 1124, 4051, 5727, 779, 3955, 4837, 2766, 6294, 6646, 4739, 5749, 6327, 858, 8677, 3651, 596, 6619, 5346, 8077, 1124, 3334, 3089, 8270, 4658, 3660, 4475, 8059, 2034, 6409, 1417, 3609, 5267, 864, 5271, 4774, 7478, 4750, 6737], [98, 7388, 8240, 939, 7812, 8014, 4907, 6758, 6, 3358, 7333, 192, 3366, 5102, 4581, 5328, 1715, 3760, 4052, 760, 2644, 1665, 1674, 5254, 1805, 1528, 6890, 4573, 1811, 8247, 4349, 3032, 2206, 343, 2447, 305, 3814, 4411, 2332, 6001, 6194, 7713, 5261, 4617, 7188, 6435, 413, 606, 4422, 3062, 3863, 7408, 4297, 7652, 112, 6895, 710, 6863]]\n",
      "Current episode: 8\n",
      "tensor([[10.2304]], grad_fn=<AddBackward0>)\n",
      "para updated\n",
      "0.061990950226244346\n",
      "0.06346153846153846\n",
      "0.06561085972850678\n",
      "0.06674208144796379\n",
      "0.0679864253393665\n",
      "Complete these jobs with 100 iterations:\n",
      "[[6219, 5586, 2234, 523, 2880, 234, 8754, 7305, 6849, 2604, 905, 1755, 2391, 8805, 7689, 8345, 8697, 7339, 753, 4237, 3726, 2836, 6105, 5473, 2992, 4027, 5873, 5095, 824, 8073, 70, 5023, 5112, 3839, 6896, 5691, 1058, 1499, 2583, 5103, 8235, 1869, 1702, 2698, 3499, 2708, 8190, 7080, 854, 2095, 4585, 4241, 8182, 4209, 1353, 2196, 7177, 3339, 8680], [6934, 4603, 3810, 1149, 5075, 1584, 5201, 1080, 966, 8470, 3028, 5240, 1508, 111, 4987, 2248, 5464, 4512, 8192, 7457, 7225, 880, 4269, 4044, 3395, 4745, 2925, 3335, 1631, 7980, 653, 2316, 1346, 8134, 8650, 2453, 8739, 2678, 1236, 5738, 6480, 1062, 104, 2888, 1502, 3974, 8626, 5005, 3932, 8238, 6392, 3621, 7286, 1932, 1135, 2855, 6552, 656, 8718, 8560, 3723, 3249], [4635, 149, 5518, 7548, 7283, 1618, 5861, 3090, 683, 8731, 2696, 8798, 2901, 986, 6902, 2124, 6829, 8309, 3710, 1470, 1183, 5289, 7679, 6791, 4055, 8028, 7175, 3074, 2720, 680, 1806, 518, 8673, 3520, 8664, 8203, 7153, 3323, 3310, 2239, 5562, 6003, 8508, 7687, 3420, 8301, 4647, 3406, 3802, 3899, 3501, 2013, 6648, 4566, 6136, 4726, 1875], [8210, 5913, 3457, 227, 5045, 7978, 3822, 8361, 2331, 8057, 8230, 541, 5276, 4100, 8771, 3425, 5492, 1226, 1384, 7377, 1395, 4625, 6782, 2014, 2298, 214, 3355, 5957, 4416, 5659, 648, 5024, 5569, 6245, 8716, 5899, 6636, 8651, 6099, 8072, 8471, 2135, 7142, 5997, 1077, 8713, 2497, 1435, 7401, 350, 5319, 6326, 2673, 6676, 695, 5773, 3678], [6574, 3879, 8522, 7313, 5582, 7972, 7355, 5745, 7565, 8269, 5003, 5853, 549, 4271, 4832, 6727, 322, 7905, 5204, 6621, 8398, 708, 4405, 6361, 2144, 1709, 3740, 5210, 6812, 3645, 5922, 5019, 2990, 323, 4531, 6785, 6117, 7318, 4901, 765, 3889, 4443, 1987, 4974, 8567, 7559, 428, 1763, 7539, 3898, 687, 4168, 6899, 4875, 7287, 493, 711, 5594, 8606, 2250, 5029, 2526], [1205, 7547, 1472, 2012, 4031, 5965, 5173, 8302, 2333, 3392, 3359, 8542, 2381, 3858, 1460, 376, 1988, 6418, 4846, 4897, 8723, 3580, 978, 7863, 1478, 2783, 1220, 5918, 3219, 3722, 4299, 5540, 6323, 3473, 2494, 7606, 3314, 6776, 500, 1762, 1259, 5740, 4845, 4680, 2760, 1064, 7105, 4374, 3302, 6989, 4864, 2550, 3735, 34, 5845, 3245], [5273, 3384, 7898, 8069, 5996, 4826, 2814, 8504, 7809, 3848, 5490, 8386, 5982, 6564, 7636, 1497, 4042, 7862, 6108, 7517, 6611, 4404, 6366, 6116, 3752, 2974, 1650, 4989, 8256, 2528, 3178, 8487, 3908, 2943, 6843, 6660, 5109, 962, 4324, 5361, 884, 3543, 7807, 2030, 110, 5714, 6414, 8544, 7330, 3957, 7837, 3011, 5213, 3847, 5126, 2097, 4905, 1524, 4994, 2900, 2443, 8215, 4472, 3989, 3382, 8312, 2238], [7857, 5684, 3454, 6478, 7839, 3472, 609, 4546, 4062, 6994, 691, 6692, 7264, 1233, 5113, 489, 1889, 6687, 1067, 3516, 6501, 8776, 2548, 8033, 1124, 4051, 5727, 779, 3955, 4837, 2766, 6294, 6646, 4739, 5749, 6327, 858, 8677, 3651, 596, 6619, 5346, 8077, 1124, 3334, 3089, 8270, 4658, 3660, 4475, 8059, 2034, 6409, 1417, 3609, 5267, 864, 5271, 4774, 7478, 4750, 6737], [98, 7388, 8240, 939, 7812, 8014, 4907, 6758, 6, 3358, 7333, 192, 3366, 5102, 4581, 5328, 1715, 3760, 4052, 760, 2644, 1665, 1674, 5254, 1805, 1528, 6890, 4573, 1811, 8247, 4349, 3032, 2206, 343, 2447, 305, 3814, 4411, 2332, 6001, 6194, 7713, 5261, 4617, 7188, 6435, 413, 606, 4422, 3062, 3863, 7408, 4297, 7652, 112, 6895, 710, 6863], [3992, 780, 2704, 240, 5151, 4518, 2368, 1600, 1933, 8700, 3733, 1784, 1974, 1114, 668, 7257, 5233, 161, 904, 3311, 4648, 3035, 6425, 4030, 2929, 578, 6974, 2033, 4976, 2534, 4535, 8511, 8366, 8464, 563, 2375, 3465, 7135, 5511, 6309, 5928, 4728, 4394, 6697, 1406, 1600, 6282, 7032, 3409, 6029, 74, 5565, 1281, 3313, 3155, 7445, 1428, 3297, 1458, 2119, 1559, 7657, 8498]]\n",
      "Current episode: 9\n"
     ]
    }
   ],
   "source": [
    "! python /workspaces/learnings/Job_Shop_Scheduling_Problem_with_Reinforcement_Learning/run.py --lr=0.01 --gamma=0.9 --seed=2020 --num-steps=100 --max-episode-length=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
