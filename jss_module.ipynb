{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12702/713697722.py:468: RuntimeWarning: invalid value encountered in divide\n",
      "  len(legal_actions), 1, p=(legal_actions / legal_actions.sum())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 467\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[1;32m    466\u001b[0m     legal_actions \u001b[38;5;241m=\u001b[39m obs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 467\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlegal_actions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlegal_actions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlegal_actions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m#actions = env.action_space.sample()\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     obs, rewards, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:971\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import gym\n",
    "import numpy as np\n",
    "import plotly.figure_factory as ff\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class JssEnv(gym.Env):\n",
    "    def __init__(self, env_config=None):\n",
    "        \"\"\"\n",
    "        This environment model the job shop scheduling problem as a single agent problem:\n",
    "\n",
    "        -The actions correspond to a job allocation + one action for no allocation at this time step (NOPE action)\n",
    "\n",
    "        -We keep a time with next possible time steps\n",
    "\n",
    "        -Each time we allocate a job, the end of the job is added to the stack of time steps\n",
    "\n",
    "        -If we don't have a legal action (i.e. we can't allocate a job),\n",
    "        we automatically go to the next time step until we have a legal action\n",
    "\n",
    "        -\n",
    "        :param env_config: Ray dictionary of config parameter\n",
    "        \"\"\"\n",
    "        if env_config is None:\n",
    "            env_config = {\n",
    "                \"instance_path\": 'Data//ta01'\n",
    "            }\n",
    "        instance_path = env_config[\"instance_path\"]\n",
    "\n",
    "        # initial values for variables used for instance\n",
    "        self.jobs = 0\n",
    "        self.machines = 0\n",
    "        self.instance_matrix = None\n",
    "        self.jobs_length = None\n",
    "        self.max_time_op = 0\n",
    "        self.max_time_jobs = 0\n",
    "        self.nb_legal_actions = 0\n",
    "        self.nb_machine_legal = 0\n",
    "        # initial values for variables used for solving (to reinitialize when reset() is called)\n",
    "        self.solution = None\n",
    "        self.last_solution = None\n",
    "        self.last_time_step = float(\"inf\")\n",
    "        self.current_time_step = float(\"inf\")\n",
    "        self.next_time_step = list()\n",
    "        self.next_jobs = list()\n",
    "        self.legal_actions = None\n",
    "        self.time_until_available_machine = None\n",
    "        self.time_until_finish_current_op_jobs = None\n",
    "        self.todo_time_step_job = None\n",
    "        self.total_perform_op_time_jobs = None\n",
    "        self.needed_machine_jobs = None\n",
    "        self.total_idle_time_jobs = None\n",
    "        self.idle_time_jobs_last_op = None\n",
    "        self.state = None\n",
    "        self.illegal_actions = None\n",
    "        self.action_illegal_no_op = None\n",
    "        self.machine_legal = None\n",
    "        # initial values for variables used for representation\n",
    "        self.start_timestamp = datetime.datetime.now().timestamp()\n",
    "        self.sum_op = 0\n",
    "        with open(instance_path, \"r\") as instance_file:\n",
    "            for line_cnt, line_str in enumerate(instance_file, start=1):\n",
    "                split_data = list(map(int, line_str.split()))\n",
    "\n",
    "                if line_cnt == 1:\n",
    "                    self.jobs, self.machines = split_data\n",
    "                    self.instance_matrix = np.zeros((self.jobs, self.machines), dtype=(int, 2))\n",
    "                    self.jobs_length = np.zeros(self.jobs, dtype=int)\n",
    "                else:\n",
    "                    assert len(split_data) % 2 == 0 and len(split_data) // 2 == self.machines\n",
    "                    job_nb = line_cnt - 2\n",
    "                    for i in range(0, len(split_data), 2):\n",
    "                        machine, time = split_data[i], split_data[i + 1]\n",
    "                        self.instance_matrix[job_nb][i // 2] = (machine, time)\n",
    "                        self.max_time_op = max(self.max_time_op, time)\n",
    "                        self.jobs_length[job_nb] += time\n",
    "                        self.sum_op += time\n",
    "        self.max_time_jobs = max(self.jobs_length)\n",
    "        # check the parsed data are correct\n",
    "        assert self.max_time_op > 0\n",
    "        assert self.max_time_jobs > 0\n",
    "        assert self.jobs > 0\n",
    "        assert self.machines > 1, \"We need at least 2 machines\"\n",
    "        assert self.instance_matrix is not None\n",
    "        # allocate a job + one to wait\n",
    "        self.action_space = gym.spaces.Discrete(self.jobs + 1)\n",
    "        # used for plotting\n",
    "        self.colors = [\n",
    "            tuple([random.random() for _ in range(3)]) for _ in range(self.machines)\n",
    "        ]\n",
    "        \"\"\"\n",
    "        matrix with the following attributes for each job:\n",
    "            -Legal job\n",
    "            -Left over time on the current op\n",
    "            -Current operation %\n",
    "            -Total left over time\n",
    "            -When next machine available\n",
    "            -Time since IDLE: 0 if not available, time otherwise\n",
    "            -Total IDLE time in the schedule\n",
    "        \"\"\"\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\n",
    "                \"action_mask\": gym.spaces.Box(0, 1, shape=(self.jobs + 1,)),\n",
    "                \"real_obs\": gym.spaces.Box(\n",
    "                    low=0.0, high=1.0, shape=(self.jobs, 7), dtype=float\n",
    "                ),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _get_current_state_representation(self):\n",
    "        self.state[:, 0] = self.legal_actions[:-1]\n",
    "        return {\n",
    "            \"real_obs\": self.state,\n",
    "            \"action_mask\": self.legal_actions,\n",
    "        }\n",
    "\n",
    "    def get_legal_actions(self):\n",
    "        return self.legal_actions\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_time_step = 0\n",
    "        self.next_time_step = list()\n",
    "        self.next_jobs = list()\n",
    "        self.nb_legal_actions = self.jobs\n",
    "        self.nb_machine_legal = 0\n",
    "        # represent all the legal actions\n",
    "        self.legal_actions = np.ones(self.jobs + 1, dtype=bool)\n",
    "        self.legal_actions[self.jobs] = False\n",
    "        # used to represent the solution\n",
    "        self.solution = np.full((self.jobs, self.machines), -1, dtype=int)\n",
    "        self.time_until_available_machine = np.zeros(self.machines, dtype=int)\n",
    "        self.time_until_finish_current_op_jobs = np.zeros(self.jobs, dtype=int)\n",
    "        self.todo_time_step_job = np.zeros(self.jobs, dtype=int)\n",
    "        self.total_perform_op_time_jobs = np.zeros(self.jobs, dtype=int)\n",
    "        self.needed_machine_jobs = np.zeros(self.jobs, dtype=int)\n",
    "        self.total_idle_time_jobs = np.zeros(self.jobs, dtype=int)\n",
    "        self.idle_time_jobs_last_op = np.zeros(self.jobs, dtype=int)\n",
    "        self.illegal_actions = np.zeros((self.machines, self.jobs), dtype=bool)\n",
    "        self.action_illegal_no_op = np.zeros(self.jobs, dtype=bool)\n",
    "        self.machine_legal = np.zeros(self.machines, dtype=bool)\n",
    "        for job in range(self.jobs):\n",
    "            needed_machine = self.instance_matrix[job][0][0]\n",
    "            self.needed_machine_jobs[job] = needed_machine\n",
    "            if not self.machine_legal[needed_machine]:\n",
    "                self.machine_legal[needed_machine] = True\n",
    "                self.nb_machine_legal += 1\n",
    "        self.state = np.zeros((self.jobs, 7), dtype=float)\n",
    "        return self._get_current_state_representation()\n",
    "\n",
    "    def _prioritization_non_final(self):\n",
    "        if self.nb_machine_legal >= 1:\n",
    "            for machine in range(self.machines):\n",
    "                if self.machine_legal[machine]:\n",
    "                    final_job = list()\n",
    "                    non_final_job = list()\n",
    "                    min_non_final = float(\"inf\")\n",
    "                    for job in range(self.jobs):\n",
    "                        if (\n",
    "                            self.needed_machine_jobs[job] == machine\n",
    "                            and self.legal_actions[job]\n",
    "                        ):\n",
    "                            if self.todo_time_step_job[job] == (self.machines - 1):\n",
    "                                final_job.append(job)\n",
    "                            else:\n",
    "                                current_time_step_non_final = self.todo_time_step_job[\n",
    "                                    job\n",
    "                                ]\n",
    "                                time_needed_legal = self.instance_matrix[job][\n",
    "                                    current_time_step_non_final\n",
    "                                ][1]\n",
    "                                machine_needed_nextstep = self.instance_matrix[job][\n",
    "                                    current_time_step_non_final + 1\n",
    "                                ][0]\n",
    "                                if (\n",
    "                                    self.time_until_available_machine[\n",
    "                                        machine_needed_nextstep\n",
    "                                    ]\n",
    "                                    == 0\n",
    "                                ):\n",
    "                                    min_non_final = min(\n",
    "                                        min_non_final, time_needed_legal\n",
    "                                    )\n",
    "                                    non_final_job.append(job)\n",
    "                    if len(non_final_job) > 0:\n",
    "                        for job in final_job:\n",
    "                            current_time_step_final = self.todo_time_step_job[job]\n",
    "                            time_needed_legal = self.instance_matrix[job][\n",
    "                                current_time_step_final\n",
    "                            ][1]\n",
    "                            if time_needed_legal > min_non_final:\n",
    "                                self.legal_actions[job] = False\n",
    "                                self.nb_legal_actions -= 1\n",
    "\n",
    "    def _check_no_op(self):\n",
    "        self.legal_actions[self.jobs] = False\n",
    "        if (\n",
    "            len(self.next_time_step) > 0\n",
    "            and self.nb_machine_legal <= 2\n",
    "            and self.nb_legal_actions <= 1\n",
    "        ):\n",
    "            machine_next = set()\n",
    "            next_time_step = self.next_time_step[0]\n",
    "            max_horizon = self.current_time_step\n",
    "            max_horizon_machine = [\n",
    "                self.current_time_step + self.max_time_op for _ in range(self.machines)\n",
    "            ]\n",
    "            for job in range(self.jobs):\n",
    "                if self.legal_actions[job]:\n",
    "                    time_step = self.todo_time_step_job[job]\n",
    "                    machine_needed = self.instance_matrix[job][time_step][0]\n",
    "                    time_needed = self.instance_matrix[job][time_step][1]\n",
    "                    end_job = self.current_time_step + time_needed\n",
    "                    if end_job < next_time_step:\n",
    "                        return\n",
    "                    max_horizon_machine[machine_needed] = min(\n",
    "                        max_horizon_machine[machine_needed], end_job\n",
    "                    )\n",
    "                    max_horizon = max(max_horizon, max_horizon_machine[machine_needed])\n",
    "            for job in range(self.jobs):\n",
    "                if not self.legal_actions[job]:\n",
    "                    if (\n",
    "                        self.time_until_finish_current_op_jobs[job] > 0\n",
    "                        and self.todo_time_step_job[job] + 1 < self.machines\n",
    "                    ):\n",
    "                        time_step = self.todo_time_step_job[job] + 1\n",
    "                        time_needed = (\n",
    "                            self.current_time_step\n",
    "                            + self.time_until_finish_current_op_jobs[job]\n",
    "                        )\n",
    "                        while (\n",
    "                            time_step < self.machines - 1 and max_horizon > time_needed\n",
    "                        ):\n",
    "                            machine_needed = self.instance_matrix[job][time_step][0]\n",
    "                            if (\n",
    "                                max_horizon_machine[machine_needed] > time_needed\n",
    "                                and self.machine_legal[machine_needed]\n",
    "                            ):\n",
    "                                machine_next.add(machine_needed)\n",
    "                                if len(machine_next) == self.nb_machine_legal:\n",
    "                                    self.legal_actions[self.jobs] = True\n",
    "                                    return\n",
    "                            time_needed += self.instance_matrix[job][time_step][1]\n",
    "                            time_step += 1\n",
    "                    elif (\n",
    "                        not self.action_illegal_no_op[job]\n",
    "                        and self.todo_time_step_job[job] < self.machines\n",
    "                    ):\n",
    "                        time_step = self.todo_time_step_job[job]\n",
    "                        machine_needed = self.instance_matrix[job][time_step][0]\n",
    "                        time_needed = (\n",
    "                            self.current_time_step\n",
    "                            + self.time_until_available_machine[machine_needed]\n",
    "                        )\n",
    "                        while (\n",
    "                            time_step < self.machines - 1 and max_horizon > time_needed\n",
    "                        ):\n",
    "                            machine_needed = self.instance_matrix[job][time_step][0]\n",
    "                            if (\n",
    "                                max_horizon_machine[machine_needed] > time_needed\n",
    "                                and self.machine_legal[machine_needed]\n",
    "                            ):\n",
    "                                machine_next.add(machine_needed)\n",
    "                                if len(machine_next) == self.nb_machine_legal:\n",
    "                                    self.legal_actions[self.jobs] = True\n",
    "                                    return\n",
    "                            time_needed += self.instance_matrix[job][time_step][1]\n",
    "                            time_step += 1\n",
    "\n",
    "    def step(self, action: int):\n",
    "        reward = 0.0\n",
    "        if action == self.jobs:\n",
    "            self.nb_machine_legal = 0\n",
    "            self.nb_legal_actions = 0\n",
    "            for job in range(self.jobs):\n",
    "                if self.legal_actions[job]:\n",
    "                    self.legal_actions[job] = False\n",
    "                    needed_machine = self.needed_machine_jobs[job]\n",
    "                    self.machine_legal[needed_machine] = False\n",
    "                    self.illegal_actions[needed_machine][job] = True\n",
    "                    self.action_illegal_no_op[job] = True\n",
    "            while self.nb_machine_legal == 0:\n",
    "                reward -= self.increase_time_step()\n",
    "            scaled_reward = self._reward_scaler(reward)\n",
    "            self._prioritization_non_final()\n",
    "            self._check_no_op()\n",
    "            return (\n",
    "                self._get_current_state_representation(),\n",
    "                scaled_reward,\n",
    "                self._is_done(),\n",
    "                {},\n",
    "            )\n",
    "        else:\n",
    "            current_time_step_job = self.todo_time_step_job[action]\n",
    "            machine_needed = self.needed_machine_jobs[action]\n",
    "            time_needed = self.instance_matrix[action][current_time_step_job][1]\n",
    "            reward += time_needed\n",
    "            self.time_until_available_machine[machine_needed] = time_needed\n",
    "            self.time_until_finish_current_op_jobs[action] = time_needed\n",
    "            self.state[action][1] = time_needed / self.max_time_op\n",
    "            to_add_time_step = self.current_time_step + time_needed\n",
    "            if to_add_time_step not in self.next_time_step:\n",
    "                index = bisect.bisect_left(self.next_time_step, to_add_time_step)\n",
    "                self.next_time_step.insert(index, to_add_time_step)\n",
    "                self.next_jobs.insert(index, action)\n",
    "            self.solution[action][current_time_step_job] = self.current_time_step\n",
    "            for job in range(self.jobs):\n",
    "                if (\n",
    "                    self.needed_machine_jobs[job] == machine_needed\n",
    "                    and self.legal_actions[job]\n",
    "                ):\n",
    "                    self.legal_actions[job] = False\n",
    "                    self.nb_legal_actions -= 1\n",
    "            self.nb_machine_legal -= 1\n",
    "            self.machine_legal[machine_needed] = False\n",
    "            for job in range(self.jobs):\n",
    "                if self.illegal_actions[machine_needed][job]:\n",
    "                    self.action_illegal_no_op[job] = False\n",
    "                    self.illegal_actions[machine_needed][job] = False\n",
    "            # if we can't allocate new job in the current timestep, we pass to the next one\n",
    "            while self.nb_machine_legal == 0 and len(self.next_time_step) > 0:\n",
    "                reward -= self.increase_time_step()\n",
    "            self._prioritization_non_final()\n",
    "            self._check_no_op()\n",
    "            # we then need to scale the reward\n",
    "            scaled_reward = self._reward_scaler(reward)\n",
    "            return (\n",
    "                self._get_current_state_representation(),\n",
    "                scaled_reward,\n",
    "                self._is_done(),\n",
    "                {},\n",
    "            )\n",
    "\n",
    "    def _reward_scaler(self, reward):\n",
    "        return reward / self.max_time_op\n",
    "\n",
    "    def increase_time_step(self):\n",
    "        \"\"\"\n",
    "        The heart of the logic his here, we need to increase every counter when we have a nope action called\n",
    "        and return the time elapsed\n",
    "        :return: time elapsed\n",
    "        \"\"\"\n",
    "        hole_planning = 0\n",
    "        next_time_step_to_pick = self.next_time_step.pop(0)\n",
    "        self.next_jobs.pop(0)\n",
    "        difference = next_time_step_to_pick - self.current_time_step\n",
    "        self.current_time_step = next_time_step_to_pick\n",
    "        for job in range(self.jobs):\n",
    "            was_left_time = self.time_until_finish_current_op_jobs[job]\n",
    "            if was_left_time > 0:\n",
    "                performed_op_job = min(difference, was_left_time)\n",
    "                self.time_until_finish_current_op_jobs[job] = max(\n",
    "                    0, self.time_until_finish_current_op_jobs[job] - difference\n",
    "                )\n",
    "                self.state[job][1] = (\n",
    "                    self.time_until_finish_current_op_jobs[job] / self.max_time_op\n",
    "                )\n",
    "                self.total_perform_op_time_jobs[job] += performed_op_job\n",
    "                self.state[job][3] = (\n",
    "                    self.total_perform_op_time_jobs[job] / self.max_time_jobs\n",
    "                )\n",
    "                if self.time_until_finish_current_op_jobs[job] == 0:\n",
    "                    self.total_idle_time_jobs[job] += difference - was_left_time\n",
    "                    self.state[job][6] = self.total_idle_time_jobs[job] / self.sum_op\n",
    "                    self.idle_time_jobs_last_op[job] = difference - was_left_time\n",
    "                    self.state[job][5] = self.idle_time_jobs_last_op[job] / self.sum_op\n",
    "                    self.todo_time_step_job[job] += 1\n",
    "                    self.state[job][2] = self.todo_time_step_job[job] / self.machines\n",
    "                    if self.todo_time_step_job[job] < self.machines:\n",
    "                        self.needed_machine_jobs[job] = self.instance_matrix[job][\n",
    "                            self.todo_time_step_job[job]\n",
    "                        ][0]\n",
    "                        self.state[job][4] = (\n",
    "                            max(\n",
    "                                0,\n",
    "                                self.time_until_available_machine[\n",
    "                                    self.needed_machine_jobs[job]\n",
    "                                ]\n",
    "                                - difference,\n",
    "                            )\n",
    "                            / self.max_time_op\n",
    "                        )\n",
    "                    else:\n",
    "                        self.needed_machine_jobs[job] = -1\n",
    "                        # this allow to have 1 is job is over (not 0 because, 0 strongly indicate that the job is a\n",
    "                        # good candidate)\n",
    "                        self.state[job][4] = 1.0\n",
    "                        if self.legal_actions[job]:\n",
    "                            self.legal_actions[job] = False\n",
    "                            self.nb_legal_actions -= 1\n",
    "            elif self.todo_time_step_job[job] < self.machines:\n",
    "                self.total_idle_time_jobs[job] += difference\n",
    "                self.idle_time_jobs_last_op[job] += difference\n",
    "                self.state[job][5] = self.idle_time_jobs_last_op[job] / self.sum_op\n",
    "                self.state[job][6] = self.total_idle_time_jobs[job] / self.sum_op\n",
    "        for machine in range(self.machines):\n",
    "            if self.time_until_available_machine[machine] < difference:\n",
    "                empty = difference - self.time_until_available_machine[machine]\n",
    "                hole_planning += empty\n",
    "            self.time_until_available_machine[machine] = max(\n",
    "                0, self.time_until_available_machine[machine] - difference\n",
    "            )\n",
    "            if self.time_until_available_machine[machine] == 0:\n",
    "                for job in range(self.jobs):\n",
    "                    if (\n",
    "                        self.needed_machine_jobs[job] == machine\n",
    "                        and not self.legal_actions[job]\n",
    "                        and not self.illegal_actions[machine][job]\n",
    "                    ):\n",
    "                        self.legal_actions[job] = True\n",
    "                        self.nb_legal_actions += 1\n",
    "                        if not self.machine_legal[machine]:\n",
    "                            self.machine_legal[machine] = True\n",
    "                            self.nb_machine_legal += 1\n",
    "        return hole_planning\n",
    "\n",
    "    def _is_done(self):\n",
    "        if self.nb_legal_actions == 0:\n",
    "            self.last_time_step = self.current_time_step\n",
    "            self.last_solution = self.solution\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        df = []\n",
    "        for job in range(self.jobs):\n",
    "            i = 0\n",
    "            while i < self.machines and self.solution[job][i] != -1:\n",
    "                dict_op = dict()\n",
    "                dict_op[\"Task\"] = \"Job {}\".format(job)\n",
    "                start_sec = self.start_timestamp + self.solution[job][i]\n",
    "                finish_sec = start_sec + self.instance_matrix[job][i][1]\n",
    "                dict_op[\"Start\"] = datetime.datetime.fromtimestamp(start_sec)\n",
    "                dict_op[\"Finish\"] = datetime.datetime.fromtimestamp(finish_sec)\n",
    "                dict_op[\"Resource\"] = \"Machine {}\".format(\n",
    "                    self.instance_matrix[job][i][0]\n",
    "                )\n",
    "                df.append(dict_op)\n",
    "                i += 1\n",
    "        fig = None\n",
    "        if len(df) > 0:\n",
    "            df = pd.DataFrame(df)\n",
    "            fig = ff.create_gantt(\n",
    "                df,\n",
    "                index_col=\"Resource\",\n",
    "                colors=self.colors,\n",
    "                show_colorbar=True,\n",
    "                group_tasks=True,\n",
    "            )\n",
    "            fig.update_yaxes(\n",
    "                autorange=\"reversed\"\n",
    "            )  # otherwise tasks are listed from the bottom up\n",
    "        return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env = JssEnv()\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    cum_reward = 0\n",
    "    #while not done:\n",
    "    for _ in range(1000):\n",
    "        legal_actions = obs[\"action_mask\"]\n",
    "        actions = np.random.choice(\n",
    "            len(legal_actions), 1, p=(legal_actions / legal_actions.sum())\n",
    "        )[0]\n",
    "        #actions = env.action_space.sample()\n",
    "        obs, rewards, done, _ = env.step(actions)\n",
    "        cum_reward += rewards\n",
    "    print(f\"Cumulative reward: {cum_reward}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs['action_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.176532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200415</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.056036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.089304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036501</td>\n",
       "      <td>0.065204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.099688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>0.064348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034787</td>\n",
       "      <td>0.062120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.184839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036586</td>\n",
       "      <td>0.057322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.096573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.064605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616162</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.156802</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051324</td>\n",
       "      <td>0.059635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.219107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>0.054494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072145</td>\n",
       "      <td>0.072145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.093458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048496</td>\n",
       "      <td>0.064862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080808</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.171340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013709</td>\n",
       "      <td>0.058435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.131880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.061691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.103842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044126</td>\n",
       "      <td>0.064005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.075805</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>0.066318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6\n",
       "0   0.0  0.000000  0.200000  0.176532  0.000000  0.000000  0.058007\n",
       "1   0.0  0.000000  0.200000  0.200415  0.000000  0.006169  0.056036\n",
       "2   0.0  0.000000  0.133333  0.089304  0.000000  0.036501  0.065204\n",
       "3   0.0  0.303030  0.133333  0.099688  0.000000  0.032816  0.064348\n",
       "4   0.0  0.606061  0.200000  0.126687  0.000000  0.034787  0.062120\n",
       "5   0.0  0.000000  0.200000  0.184839  0.000000  0.036586  0.057322\n",
       "6   0.0  0.202020  0.133333  0.096573  0.000000  0.028361  0.064605\n",
       "7   0.0  0.616162  0.266667  0.156802  0.000000  0.051324  0.059635\n",
       "8   0.0  0.919192  0.200000  0.219107  0.000000  0.020135  0.054494\n",
       "9   0.0  0.000000  0.066667  0.005192  0.000000  0.072145  0.072145\n",
       "10  0.0  0.000000  0.066667  0.093458  0.000000  0.048496  0.064862\n",
       "11  0.0  0.080808  0.200000  0.171340  0.000000  0.013709  0.058435\n",
       "12  0.0  0.000000  0.133333  0.131880  0.000000  0.000857  0.061691\n",
       "13  0.0  0.757576  0.200000  0.103842  0.000000  0.044126  0.064005\n",
       "14  0.0  0.000000  0.133333  0.075805  0.343434  0.039500  0.066318"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs1=pd.DataFrame(obs['real_obs'])\n",
    "obs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12702/1622096392.py:10: RuntimeWarning: invalid value encountered in divide\n",
      "  actions = np.random.choice(len(legal_actions), 1, p=(legal_actions / legal_actions.sum()))[0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "probabilities contain NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m c_rewards\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2000\u001b[39m):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#actions = env.action_space.sample()\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlegal_actions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlegal_actions\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlegal_actions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m     obs, rewards, done, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m#print(\"action mask:\", obs['action_mask'])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#print(\" obs:\", obs['real_obs'])\u001b[39;00m\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:971\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: probabilities contain NaN"
     ]
    }
   ],
   "source": [
    "env = JssEnv()\n",
    "obs = env.reset()\n",
    "done = False\n",
    "cum_reward = 0\n",
    "\n",
    "c_obs=[]\n",
    "c_rewards=[]\n",
    "for _ in range(2000):\n",
    "    #actions = env.action_space.sample()\n",
    "    actions = np.random.choice(len(legal_actions), 1, p=(legal_actions / legal_actions.sum()))[0]\n",
    "    obs, rewards, done, _ = env.step(actions)\n",
    "    #print(\"action mask:\", obs['action_mask'])\n",
    "    #print(\" obs:\", obs['real_obs'])\n",
    "\n",
    "    cum_reward += rewards\n",
    "    c_obs.append(obs['real_obs'][2])\n",
    "    c_rewards.append(rewards)\n",
    "\n",
    "\n",
    "print(f\"Cumulative reward: {cum_reward}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
